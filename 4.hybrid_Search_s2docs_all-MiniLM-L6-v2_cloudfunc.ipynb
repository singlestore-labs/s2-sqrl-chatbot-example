{"cells":[{"attachments":{},"cell_type":"markdown","id":"33b073ec","metadata":{},"source":"<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/browser.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">Cloud Function</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Docs Chunks Hybrid Search Cloud Function</h1>\n    </div>\n</div>"},{"cell_type":"code","execution_count":13,"id":"a5e904e6-1632-44dd-b6c3-a1d842ba7f9a","metadata":{"execution":{"iopub.execute_input":"2025-03-06T23:51:25.813577Z","iopub.status.busy":"2025-03-06T23:51:25.813292Z","iopub.status.idle":"2025-03-06T23:53:14.345343Z","shell.execute_reply":"2025-03-06T23:53:14.305251Z","shell.execute_reply.started":"2025-03-06T23:51:25.813553Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip install -q sentence_transformers"},{"attachments":{},"cell_type":"markdown","id":"dd5f2dea","metadata":{},"source":"## Setup Environment\n\nLets setup the environment ro run a FastAPI app defining the Data Model and an executor to run the different requests in different threads simultaneously"},{"cell_type":"code","execution_count":14,"id":"225f1ba8","metadata":{"execution":{"iopub.execute_input":"2025-03-06T23:53:14.412814Z","iopub.status.busy":"2025-03-06T23:53:14.409802Z","iopub.status.idle":"2025-03-06T23:53:22.252429Z","shell.execute_reply":"2025-03-06T23:53:22.251843Z","shell.execute_reply.started":"2025-03-06T23:53:14.412754Z"},"language":"python","trusted":true},"outputs":[],"source":"import json\nimport torch\nimport singlestoredb as s2\nimport singlestoredb.apps as apps\nfrom pydantic import BaseModel\nfrom sentence_transformers import SentenceTransformer\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.concurrency import run_in_threadpool"},{"cell_type":"code","execution_count":15,"id":"3c77793f-b243-4cd9-983e-8f570064c5cd","metadata":{"execution":{"iopub.execute_input":"2025-03-06T23:53:22.254033Z","iopub.status.busy":"2025-03-06T23:53:22.253569Z","iopub.status.idle":"2025-03-06T23:53:22.257409Z","shell.execute_reply":"2025-03-06T23:53:22.256977Z","shell.execute_reply.started":"2025-03-06T23:53:22.254015Z"},"language":"python","trusted":true},"outputs":[],"source":"def connect_to_db(database_name='knowlagent'):\n    \"\"\"Return a new SingleStore DB connection.\"\"\"\n    return s2.connect(database=database_name)"},{"cell_type":"code","execution_count":16,"id":"94076020-d80c-4279-a394-a3b255942f10","metadata":{"execution":{"iopub.execute_input":"2025-03-06T23:53:22.258711Z","iopub.status.busy":"2025-03-06T23:53:22.258302Z","iopub.status.idle":"2025-03-06T23:53:22.264956Z","shell.execute_reply":"2025-03-06T23:53:22.264548Z","shell.execute_reply.started":"2025-03-06T23:53:22.258683Z"},"language":"python","trusted":true},"outputs":[],"source":"#########################################\n#  Hybrid Search Function               #\n#########################################\ndef hybrid_search(query_text, model_name='all-MiniLM-L6-v2', top_k=5, vector_weight=0.7, text_weight=0.3):\n    \"\"\"\n    Perform a hybrid search using both vector similarity and fulltext matches.\n    If the fulltext index is not found, fall back to a vector-only search.\n    This version computes the individual scores in a subquery, then combines them.\n    \"\"\"\n    conn = connect_to_db()\n    table_name = f\"s2docs_chunks_{model_name.replace('-', '_').replace('/', '_')}\"\n    \n    try:\n        # Initialize the embedding model and encode the query.\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        embed_model = SentenceTransformer(model_name, device=device)\n        query_embedding = embed_model.encode(query_text).tolist()\n        query_embedding_json = json.dumps(query_embedding)\n        \n        with conn.cursor() as cursor:\n            # Check if the FULLTEXT index exists.\n            cursor.execute(f\"\"\"\n                SELECT COUNT(*) \n                FROM information_schema.statistics \n                WHERE table_schema = DATABASE() \n                  AND table_name = '{table_name}' \n                  AND index_name = 'idx_{table_name}_text'\n            \"\"\")\n            has_fulltext = cursor.fetchone()[0] > 0\n            \n            if has_fulltext:\n                hybrid_sql = f\"\"\"\n                SELECT \n                    doc_id,\n                    source_url,\n                    chunk_index,\n                    chunk_text,\n                    -- combine the fulltext score (ft_score) and vector score (vt_score)\n                    (ft_score * {text_weight} + vt_score * {vector_weight}) AS score\n                FROM (\n                    SELECT \n                        doc_id,\n                        source_url,\n                        chunk_index,\n                        chunk_text,\n                        DOT_PRODUCT(vector_embedding, JSON_ARRAY_PACK(%s)) AS vt_score,\n                        MATCH(chunk_text) AGAINST(%s) AS ft_score\n                    FROM {table_name}\n                    WHERE MATCH(chunk_text) AGAINST(%s)\n                ) AS sub\n                ORDER BY score DESC\n                LIMIT %s\n                \"\"\"\n                cursor.execute(hybrid_sql, (query_embedding_json, query_text, query_text, top_k))\n            else:\n                print(\"FULLTEXT index not found. Falling back to vector-only search.\")\n                vector_sql = f\"\"\"\n                SELECT \n                    doc_id,\n                    source_url,\n                    chunk_index,\n                    chunk_text,\n                    DOT_PRODUCT(vector_embedding, JSON_ARRAY_PACK(%s)) AS score\n                FROM {table_name}\n                ORDER BY score DESC\n                LIMIT %s\n                \"\"\"\n                cursor.execute(vector_sql, (query_embedding_json, top_k))\n            \n            results = cursor.fetchall()\n        return results\n    except Exception as e:\n        print(\"Error during hybrid search:\", e)\n        return []\n    finally:\n        conn.close()"},{"attachments":{},"cell_type":"markdown","id":"d58c8382","metadata":{},"source":"## Define FastAPI App\n\nNext, we will be defining a FastAPI app that can insert, query and delete data from your table"},{"cell_type":"code","execution_count":17,"id":"f3f3b047","metadata":{"execution":{"iopub.execute_input":"2025-03-06T23:53:22.266603Z","iopub.status.busy":"2025-03-06T23:53:22.266394Z","iopub.status.idle":"2025-03-06T23:53:22.296198Z","shell.execute_reply":"2025-03-06T23:53:22.295570Z","shell.execute_reply.started":"2025-03-06T23:53:22.266581Z"},"language":"python","trusted":true},"outputs":[],"source":"def query_hybrid(query_text, model_name, top_k, vector_weight, text_weight):\n    \"\"\"Wrapper to call hybrid_search with provided parameters.\"\"\"\n    return hybrid_search(query_text, model_name=model_name, top_k=top_k,\n                         vector_weight=vector_weight, text_weight=text_weight)\n\n# Define a Pydantic model for the search request.\nclass SearchRequest(BaseModel):\n    query_text: str\n    top_k: int = 5\n    vector_weight: float = 0.7\n    text_weight: float = 0.3\n    model_name: str = \"all-MiniLM-L6-v2\"\n\napp = FastAPI()\n\n# Endpoint that accepts search parameters via the request body.\n@app.post(\"/v2/search\")\nasync def get_chunks(request: SearchRequest):\n    try:\n        # Run the blocking query_hybrid in a separate thread.\n        results = await run_in_threadpool(\n            query_hybrid,\n            request.query_text,\n            request.model_name,\n            request.top_k,\n            request.vector_weight,\n            request.text_weight\n        )\n        return {\"results\": results}\n    except HTTPException as e:\n        raise e\n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Error fetching results for search '{request.query_text}': {str(e)}\"\n        )\n\n\n# Get search for chunks by query\n@app.get(\"/v1/search/{query_text}\")\nasync def get_chunks(query_text: str):\n    try:\n        # Run the blocking query_hybrid in a separate thread\n        results = await run_in_threadpool(query_hybrid, query_text, \"all-MiniLM-L6-v2\", 10, 0.8, 0.2)\n        return {\"results\": results}\n    except HTTPException as e:\n        raise e\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching results for search '{query_text}': {str(e)}\")"},{"attachments":{},"cell_type":"markdown","id":"40e2ad59","metadata":{},"source":"## Start the FastAPI server"},{"cell_type":"code","execution_count":18,"id":"ed4b22cd","metadata":{"execution":{"iopub.execute_input":"2025-03-06T23:53:22.297275Z","iopub.status.busy":"2025-03-06T23:53:22.297049Z","iopub.status.idle":"2025-03-06T23:53:22.399135Z","shell.execute_reply":"2025-03-06T23:53:22.398679Z","shell.execute_reply.started":"2025-03-06T23:53:22.297247Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Cloud function available at https://apps.aws-virginia-nb2.svc.singlestore.com:8000/notebooks/InteractiveNotebook/3a0711ab-89e7-42cd-8863-322277d5a125/app/docs?authToken=eyJhbGciOiJFUzUxMiIsImtpZCI6IjhhNmVjNWFmLThlNWEtNDQxOS04NmM4LWRkMDkxN2U1YWNlMSIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI1YjQ1OTgxYy04YjA5LTRlYWQtYmVjMC0wOTU0N2Q3YjlhOTciLCJhdWQiOlsibm92YXB1YmxpYyJdLCJleHAiOjE3NDEzMDUyOTAsIm5iZiI6MTc0MTMwNDk5MCwiaWF0IjoxNzQxMzA0OTkwLCJqdGkiOiI5ZTAzZTFlMy02ZDk1LTQ4ZjktYmQ2NS1mYzgzNzgzMWVhNjgiLCJjb250YWluZXJJRCI6IjNhMDcxMWFiLTg5ZTctNDJjZC04ODYzLTMyMjI3N2Q1YTEyNSJ9.ABZZC30tpD5w-olY1OdgLk_M46x857u6UZ_jmcOibaV-PQjnu9M78N0j7OCB8jKs8XsfCudNPOIuWetPUcL1doNoALMV5FrX25hEH0vqGn6d_v4EXi2WeeFMFoyR5f77ngGqq4i_yGxgGc1NMjklC7VtApAQo2Ko4pNLMn2nBixE2apX\n"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af67142ae08a4c56a68dc29b66d723d8","version_major":2,"version_minor":0},"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f80d73e1fa1b401fa59bdb89c695abcc","version_major":2,"version_minor":0},"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81aa55289aec464eb5397dd5c5401abf","version_major":2,"version_minor":0},"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af9467255a7f4bd2ac5431f9f603d846","version_major":2,"version_minor":0},"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a1e3703efa24e4ab1c5a4f5c3dd0158","version_major":2,"version_minor":0},"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b10cf68212642f097a1a93983a71cf7","version_major":2,"version_minor":0},"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e49d79f9607439eb413e7dd93688172","version_major":2,"version_minor":0},"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b19ca7960a214ae189b9ea8b71f2d1ca","version_major":2,"version_minor":0},"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de8982702bb645a6b388c38cfdcb4b46","version_major":2,"version_minor":0},"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf36fc9ac67a4e319dabed8d629b27d8","version_major":2,"version_minor":0},"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d524a5cf68a46d7a2bdcd1062b64c18","version_major":2,"version_minor":0},"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"}],"source":"connection_info = await apps.run_function_app(app)"},{"attachments":{},"cell_type":"markdown","id":"b6c75678","metadata":{},"source":"<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"","defaultDatabase":""},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}